pip install -r requirements.txt


import streamlit as st
import pandas as pd
import numpy as np
import os
import datetime
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from utils.preprocessing import load_data, preprocess_data, create_sequences, get_selected_features
from utils.model_utils import (
    load_models, predict_rf, predict_lstm, 
    evaluate_model, visualize_predictions, get_feature_importance
)

# Configuration de la page
st.set_page_config(page_title="Maintenance Pr√©dictive", page_icon="üîç", layout="wide")

# Chemins des fichiers
MODELS_DIR = "models"
RF_MODEL_PATH = os.path.join(MODELS_DIR, "modele_random_forest.pkl")
LSTM_MODEL_PATH = os.path.join(MODELS_DIR, "modele_lstm.h5")
SCALER_PATH = os.path.join(MODELS_DIR, "scaler.pkl")

# Fonction pour v√©rifier si les mod√®les existent
def check_models_exist():
    return all(os.path.exists(p) for p in [RF_MODEL_PATH, LSTM_MODEL_PATH, SCALER_PATH])

# Titre de l'application
st.title("üîç Application de Maintenance Pr√©dictive")
st.markdown("""
Cette application utilise des mod√®les d'apprentissage automatique (Random Forest et LSTM) 
pour pr√©dire les d√©faillances d'√©quipements √† partir de donn√©es de capteurs (pression et d√©bit).
""")

# Sidebar
st.sidebar.title("Navigation")
page = st.sidebar.radio("S√©lectionnez une page", ["Accueil", "Analyse de donn√©es", "Pr√©dictions", "√âvaluation des mod√®les", "√Ä propos"])

# V√©rifier l'existence des mod√®les
models_exist = check_models_exist()
if not models_exist:
    st.warning("‚ö†Ô∏è Les mod√®les entra√Æn√©s n'ont pas √©t√© trouv√©s. Veuillez ex√©cuter le script d'entra√Ænement d'abord.")

# Page d'accueil
if page == "Accueil":
    st.header("üìä Syst√®me de Maintenance Pr√©dictive")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Objectifs du projet")
        st.markdown("""
        - **Pr√©dire les d√©faillances** avant qu'elles ne se produisent
        - **R√©duire les temps d'arr√™t** des √©quipements
        - **Optimiser les interventions** de maintenance
        - **Am√©liorer la fiabilit√©** des syst√®mes
        """)
        
        st.subheader("Mod√®les utilis√©s")
        st.markdown("""
        1. **Random Forest**: Un mod√®le robuste pour la classification qui utilise plusieurs arbres de d√©cision
        2. **LSTM (Long Short-Term Memory)**: Un r√©seau de neurones r√©current adapt√© aux s√©quences temporelles
        """)
    
    with col2:
        st.subheader("Comment utiliser cette application")
        st.markdown("""
        1. **Analyse de donn√©es**: Visualisez et explorez les donn√©es des capteurs
        2. **Pr√©dictions**: T√©l√©chargez de nouvelles donn√©es pour pr√©dire les d√©faillances
        3. **√âvaluation des mod√®les**: Examinez les performances des mod√®les
        4. **√Ä propos**: Informations sur le d√©veloppement de ce projet
        """)
        
        st.info("üí° Pour commencer, chargez des donn√©es dans l'onglet 'Analyse de donn√©es' ou 'Pr√©dictions'")

# Page d'analyse de donn√©es
elif page == "Analyse de donn√©es":
    st.header("üìà Analyse de donn√©es")
    
    # Upload de fichier
    uploaded_file = st.file_uploader("Chargez un fichier CSV", type=["csv"])
    
    if uploaded_file is not None:
        try:
            # Charger les donn√©es
            df = load_data(uploaded_file)
            st.success(f"‚úÖ Donn√©es charg√©es avec succ√®s: {df.shape[0]} lignes et {df.shape[1]} colonnes")
            
            # Afficher les informations des donn√©es
            st.subheader("Aper√ßu des donn√©es")
            st.dataframe(df.head())
            
            # Statistiques descriptives
            st.subheader("Statistiques descriptives")
            st.dataframe(df.describe())
            
            # Visualisation des donn√©es temporelles
            st.subheader("√âvolution temporelle de la pression et du d√©bit")
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df['Time'], y=df['pression'], name='Pression', line=dict(color='blue')))
            fig.add_trace(go.Scatter(x=df['Time'], y=df['debit'], name='D√©bit', line=dict(color='green'), yaxis='y2'))
            
            fig.update_layout(
                title='√âvolution de la pression et du d√©bit au fil du temps',
                xaxis_title='Date et heure',
                yaxis_title='Pression',
                yaxis2=dict(
                    title='D√©bit',
                    overlaying='y',
                    side='right'
                ),
                height=600
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Analyse de corr√©lation
            st.subheader("Corr√©lation entre pression et d√©bit")
            fig = go.Figure(go.Scatter(
                x=df['pression'],
                y=df['debit'],
                mode='markers',
                marker=dict(
                    size=6,
                    color=df['Time'].astype(int),
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title='Temps')
                )
            ))
            
            fig.update_layout(
                title='Corr√©lation entre pression et d√©bit',
                xaxis_title='Pression',
                yaxis_title='D√©bit',
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Distributions
            st.subheader("Distribution des variables")
            col1, col2 = st.columns(2)
            
            with col1:
                fig = go.Figure()
                fig.add_trace(go.Histogram(x=df['pression'], nbinsx=30, name='Pression'))
                fig.update_layout(title='Distribution de la pression', xaxis_title='Pression', yaxis_title='Fr√©quence')
                st.plotly_chart(fig, use_container_width=True)
                
            with col2:
                fig = go.Figure()
                fig.add_trace(go.Histogram(x=df['debit'], nbinsx=30, name='D√©bit'))
                fig.update_layout(title='Distribution du d√©bit', xaxis_title='D√©bit', yaxis_title='Fr√©quence')
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erreur lors du chargement des donn√©es: {str(e)}")
    else:
        st.info("‚¨ÜÔ∏è Veuillez charger un fichier CSV pour commencer l'analyse")

# Page de pr√©dictions
elif page == "Pr√©dictions":
    st.header("üîÆ Pr√©dictions de d√©faillances")
    
    if not models_exist:
        st.error("Mod√®les non disponibles. Veuillez ex√©cuter le script d'entra√Ænement.")
    else:
        # Upload de fichier
        uploaded_file = st.file_uploader("Chargez un fichier CSV pour les pr√©dictions", type=["csv"])
        
        if uploaded_file is not None:
            try:
                # Charger les donn√©es
                df = load_data(uploaded_file)
                st.success(f"‚úÖ Donn√©es charg√©es avec succ√®s: {df.shape[0]} lignes")
                
                # Pr√©traitement des donn√©es
                with st.spinner("Pr√©traitement des donn√©es..."):
                    X_scaled, _, df_features = preprocess_data(df, SCALER_PATH, with_target=False)
                
                # Chargement des mod√®les
                with st.spinner("Chargement des mod√®les..."):
                    rf_model, lstm_model = load_models(RF_MODEL_PATH, LSTM_MODEL_PATH)
                
                # Pr√©dictions
                with st.spinner("G√©n√©ration des pr√©dictions..."):
                    # Random Forest
                    y_pred_rf, y_pred_proba_rf = predict_rf(rf_model, X_scaled)
                    
                    # LSTM (s√©quence de 60 points)
                    y_pred_lstm, y_pred_proba_lstm = predict_lstm(lstm_model, X_scaled, seq_length=60)
                
                st.success("‚úÖ Pr√©dictions g√©n√©r√©es avec succ√®s")
                
                # Affichage des r√©sultats
                st.subheader("R√©sultats des pr√©dictions")
                
                # Nombre d'alertes d√©tect√©es
                rf_alerts = sum(y_pred_rf == 1)
                lstm_alerts = sum(~np.isnan(y_pred_lstm) & (y_pred_lstm == 1))
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Alertes Random Forest", rf_alerts)
                with col2:
                    st.metric("Alertes LSTM", lstm_alerts)
                
                # Visualisation des pr√©dictions
                st.subheader("Visualisation des pr√©dictions")
                fig = visualize_predictions(df_features, y_pred_rf, y_pred_proba_rf, y_pred_lstm, y_pred_proba_lstm)
                st.plotly_chart(fig, use_container_width=True)
                
                # Tableau des alertes d√©tect√©es
                st.subheader("D√©tails des alertes")
                
                # Combiner les alertes des deux mod√®les
                all_alerts = []
                
                # Alertes RF
                rf_alert_indices = np.where(y_pred_rf == 1)[0]
                for idx in rf_alert_indices:
                    all_alerts.append({
                        'Date': df_features['Time'].iloc[idx],
                        'Mod√®le': 'Random Forest',
                        'Probabilit√©': y_pred_proba_rf[idx],
                        'Pression': df_features['pression'].iloc[idx],
                        'D√©bit': df_features['debit'].iloc[idx]
                    })
                
                # Alertes LSTM
                lstm_alert_indices = np.where((~np.isnan(y_pred_lstm)) & (y_pred_lstm == 1))[0]
                for idx in lstm_alert_indices:
                    all_alerts.append({
                        'Date': df_features['Time'].iloc[idx],
                        'Mod√®le': 'LSTM',
                        'Probabilit√©': y_pred_proba_lstm[idx],
                        'Pression': df_features['pression'].iloc[idx],
                        'D√©bit': df_features['debit'].iloc[idx]
                    })
                
                if all_alerts:
                    alerts_df = pd.DataFrame(all_alerts)
                    alerts_df = alerts_df.sort_values('Date')
                    st.dataframe(alerts_df)
                    
                    # Exportation des alertes
                    csv = alerts_df.to_csv(index=False)
                    st.download_button(
                        label="T√©l√©charger les alertes (CSV)",
                        data=csv,
                        file_name="alertes_maintenance.csv",
                        mime="text/csv",
                    )
                else:
                    st.info("Aucune alerte d√©tect√©e dans les donn√©es.")
                
                # Importance des caract√©ristiques (Random Forest)
                st.subheader("Importance des caract√©ristiques (Random Forest)")
                feature_names = get_selected_features()
                fig = get_feature_importance(rf_model, feature_names)
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration des pr√©dictions: {str(e)}")
                st.exception(e)
        else:
            st.info("‚¨ÜÔ∏è Veuillez charger un fichier CSV pour g√©n√©rer des pr√©dictions")

# Page d'√©valuation des mod√®les
elif page == "√âvaluation des mod√®les":
    st.header("üìä √âvaluation des mod√®les")
    
    if not models_exist:
        st.error("Mod√®les non disponibles. Veuillez ex√©cuter le script d'entra√Ænement.")
    else:
        # Upload de fichier avec la v√©rit√© terrain
        st.warning("‚ö†Ô∏è Pour √©valuer les mod√®les, veuillez charger un fichier contenant la v√©rit√© terrain (target)")
        uploaded_file = st.file_uploader("Chargez un fichier CSV avec la v√©rit√© terrain", type=["csv"])
        
        # Option pour d√©finir les dates d'√©chec
        use_dates = st.checkbox("D√©finir manuellement les dates d'√©chec")
        dates_echec = []
        
        if use_dates:
            st.subheader("Dates d'√©chec")
            
            # Interface pour ajouter des dates d'√©chec
            col1, col2 = st.columns([3, 1])
            with col1:
                new_date = st.text_input("Nouvelle date d'√©chec (format: DD.MM.YYYY HH:MM:SS.ffffff)", 
                                         placeholder="ex: 23.11.2024 7:50:18.870000")
            with col2:
                add_button = st.button("Ajouter")
            
            if add_button and new_date:
                try:
                    dates_echec.append(pd.to_datetime(new_date, format='%d.%m.%Y %H:%M:%S.%f'))
                    st.success(f"Date ajout√©e: {new_date}")
                except:
                    st.error("Format de date invalide")
            
            # Afficher les dates ajout√©es
            if dates_echec:
                st.write("Dates d'√©chec d√©finies:")
                for i, date in enumerate(dates_echec):
                    st.write(f"{i+1}. {date.strftime('%d.%m.%Y %H:%M:%S.%f')}")
        
        if uploaded_file is not None:
            try:
                # Charger les donn√©es
                df = load_data(uploaded_file)
                st.success(f"‚úÖ Donn√©es charg√©es avec succ√®s: {df.shape[0]} lignes")
                
                # Pr√©traitement
                if use_dates and dates_echec:
                    # Utiliser les dates d'√©chec d√©finies manuellement
                    X_scaled, y, df_features = preprocess_data(df, SCALER_PATH, with_target=False)
                    df_features = create_features(df, dates_echec)
                    y = df_features['target']
                else:
                    # V√©rifier si les donn√©es contiennent d√©j√† la colonne target
                    if 'target' in df.columns:
                        X_scaled, y, df_features = preprocess_data(df, SCALER_PATH, with_target=True)
                    else:
                        st.error("Le fichier ne contient pas de colonne 'target' et aucune date d'√©chec n'a √©t√© d√©finie.")
                        st.stop()
                
                # Chargement des mod√®les
                rf_model, lstm_model = load_models(RF_MODEL_PATH, LSTM_MODEL_PATH)
                
                # Pr√©dictions
                # Random Forest
                y_pred_rf, y_pred_proba_rf = predict_rf(rf_model, X_scaled)
                
                # LSTM
                y_pred_lstm, y_pred_proba_lstm = predict_lstm(lstm_model, X_scaled, seq_length=60)
                
                # √âvaluation des mod√®les
                st.subheader("√âvaluation du mod√®le Random Forest")
                fig_rf, metrics_rf = evaluate_model(y, y_pred_rf, y_pred_proba_rf, "Random Forest")
                st.plotly_chart(fig_rf, use_container_width=True)
                st.dataframe(metrics_rf)
                
                # Filtrer les donn√©es pour le LSTM (ignorer les NaN)
                valid_indices = ~np.isnan(y_pred_lstm)
                if valid_indices.any():
                    st.subheader("√âvaluation du mod√®le LSTM")
                    fig_lstm, metrics_lstm = evaluate_model(
                        y[valid_indices], 
                        y_pred_lstm[valid_indices], 
                        y_pred_proba_lstm[valid_indices], 
                        "LSTM"
                    )
                    st.plotly_chart(fig_lstm, use_container_width=True)
                    st.dataframe(metrics_lstm)
                else:
                    st.warning("Impossible d'√©valuer le mod√®le LSTM car aucune pr√©diction valide n'a √©t√© g√©n√©r√©e.")
                
                # Visualisation des pr√©dictions
                st.subheader("Visualisation des pr√©dictions vs v√©rit√© terrain")
                
                fig = go.Figure()
                
                # Donn√©es de v√©rit√© terrain
                fig.add_trace(go.Scatter(x=df_features['Time'], y=y, name='V√©rit√© terrain', mode='markers',
                                       marker=dict(color='black', size=10, symbol='x')))
                
                # Pr√©dictions RF
                fig.add_trace(go.Scatter(x=df_features['Time'], y=y_pred_proba_rf, name='Probabilit√© RF', 
                                       line=dict(color='red')))
                
                # Pr√©dictions LSTM
                fig.add_trace(go.Scatter(x=df_features['Time'][valid_indices], y=y_pred_proba_lstm[valid_indices], 
                                       name='Probabilit√© LSTM', line=dict(color='blue')))
                
                # Seuil de d√©cision
                fig.add_shape(type="line", x0=df_features['Time'].iloc[0], x1=df_features['Time'].iloc[-1], 
                             y0=0.5, y1=0.5, line=dict(color="gray", width=1, dash="dash"))
                
                fig.update_layout(
                    title="Pr√©dictions vs v√©rit√© terrain",
                    xaxis_title="Date et heure",
                    yaxis_title="Probabilit√© / V√©rit√© terrain",
                    height=600
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Erreur lors de l'√©valuation des mod√®les: {str(e)}")
                st.exception(e)
        else:
            st.info("‚¨ÜÔ∏è Veuillez charger un fichier CSV pour √©valuer les mod√®les")

# Page √Ä propos
elif page == "√Ä propos":
    st.header("‚ÑπÔ∏è √Ä propos du projet")
    
    st.subheader("Projet de maintenance pr√©dictive")
    st.markdown("""
    Cette application a √©t√© d√©velopp√©e dans le cadre d'un projet de fin d'√©tudes en maintenance pr√©dictive.
    Elle utilise des techniques d'apprentissage automatique pour pr√©dire les d√©faillances d'√©quipements √† partir
    de donn√©es de capteurs (pression et d√©bit).
    """)
    
    st.subheader("Mod√®les utilis√©s")
    st.markdown("""
    #### 1. Random Forest
    Le mod√®le Random Forest est un ensemble d'arbres de d√©cision qui:
    - Est robuste contre le surapprentissage
    - Peut g√©rer des donn√©es non lin√©aires
    - Fournit une mesure d'importance des caract√©ristiques
    
    #### 2. LSTM (Long Short-Term Memory)
    Le mod√®le LSTM est un type de r√©seau de neurones r√©current qui:
    - Est sp√©cialement con√ßu pour les s√©quences temporelles
    - Peut capturer des d√©pendances √† long terme
    - Est adapt√© aux probl√®mes de pr√©diction de s√©ries temporelles
    """)
    
    st.subheader("Structure du projet")
    st.markdown("""
    ```
    maintenance_predictive/
    ‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances du projet
    ‚îú‚îÄ‚îÄ train.py                  # Script d'entra√Ænement
    ‚îú‚îÄ‚îÄ models/                   # Dossier contenant les mod√®les entra√Æn√©s
    ‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl
    ‚îÇ   ‚îú‚îÄ‚îÄ modele_random_forest.pkl
    ‚îÇ   ‚îî‚îÄ‚îÄ modele_lstm.h5
    ‚îú‚îÄ‚îÄ data/                     # Dossier pour les donn√©es
    ‚îÇ   ‚îî‚îÄ‚îÄ ba9.csv               # Donn√©es d'origine
    ‚îú‚îÄ‚îÄ utils/                    # Utilitaires
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py      # Fonctions de pr√©traitement
    ‚îÇ   ‚îî‚îÄ‚îÄ model_utils.py        # Fonctions li√©es aux mod√®les
    ‚îî‚îÄ‚îÄ app.py                    # Application principale avec interface
    ```
    """)
    
    st.subheader("Comment utiliser cette application")
    st.markdown("""
    1. **Entra√Ænement des mod√®les**: Ex√©cutez `train.py` pour entra√Æner les mod√®les
    2. **Lancement de l'application**: Ex√©cutez `streamlit run app.py` pour d√©marrer l'application
    3. **Exploration**: Utilisez les diff√©rentes pages pour analyser les donn√©es et g√©n√©rer des pr√©dictions
    """)
    
    st.subheader("Pr√©requis")
    st.markdown("""
    L'application n√©cessite les biblioth√®ques Python suivantes:
    - scikit-learn==1.2.2
    - joblib==1.2.0
    - tensorflow==2.13.0
    - pandas==2.0.3
    - numpy==1.24.3
    - matplotlib==3.7.2
    - seaborn==0.12.2
    - streamlit==1.27.0
    - plotly==5.16.1
    
    Installation: `pip install -r requirements.txt`
    """)